{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7f4ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 21:58:04.684359: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-04 21:58:04.730875: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.8/dist-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/usr/local/lib/python3.8/dist-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/usr/local/lib/python3.8/dist-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/usr/local/lib/python3.8/dist-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "## Librerías\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import cv2 as cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import gc\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uso de GPU\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33df60e5",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c370849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rutas de todas las imágenes\n",
    "\n",
    "## Obtener todas las rutas de las imágenes en el dataset\n",
    "ruta_dataset  = glob.glob('/home/willy98/archivos/Datasets/SH_procesadas/Recortadas_grises/*/*/*/*.jpg')\n",
    "\n",
    "## Capturar solo rutas secas \n",
    "rutas_imagenes_secas = []\n",
    "rutas_imagenes_humedas = []\n",
    "\n",
    "clases_secas= []\n",
    "clases_humedas = []\n",
    "for ruta in ruta_dataset:\n",
    "    if ruta.split('/')[-2] == 'Secas' or ruta.split('/')[-2] == 'Seca':\n",
    "        clases_secas.append(ruta.split('/')[-4])\n",
    "        rutas_imagenes_secas.append(ruta)\n",
    "    else:\n",
    "        clases_humedas.append(ruta.split('/')[-4])\n",
    "        rutas_imagenes_humedas.append(ruta)\n",
    "\n",
    "## Construcción de datasets\n",
    "data_secas = pd.DataFrame({'ruta':rutas_imagenes_secas,'clase':clases_secas})\n",
    "data_humedas = pd.DataFrame({'ruta':rutas_imagenes_humedas,'clase':clases_humedas})\n",
    "\n",
    "## reemplazo de etiquetas}\n",
    "lables_generalization = {'CuNi1':'MF1','CuNi2':'MF2','CuNi3':'MF3'}\n",
    "data_secas.replace(lables_generalization,inplace=True)\n",
    "data_humedas.replace(lables_generalization,inplace=True)\n",
    "\n",
    "## summary    \n",
    "print('Imágenes secas:', np.shape(rutas_imagenes_secas)[0],' - Imágenes Húmedas: ',np.shape(rutas_imagenes_humedas)[0])\n",
    "print('MF1:', '- secas: ', np.shape(data_secas[data_secas['clase']=='MF1'])[0], '- húmedas: ', np.shape(data_humedas[data_humedas['clase']=='MF1'])[0])\n",
    "print('MF2:', '- secas: ', np.shape(data_secas[data_secas['clase']=='MF2'])[0], '- húmedas: ', np.shape(data_humedas[data_humedas['clase']=='MF2'])[0])\n",
    "print('MF3:', '- secas: ', np.shape(data_secas[data_secas['clase']=='MF3'])[0], '- húmedas: ', np.shape(data_humedas[data_humedas['clase']=='MF3'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c8c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crear Dataframe\n",
    "df_secas = pd.DataFrame()\n",
    "df_secas['routes'] = rutas_imagenes_secas\n",
    "df_secas['label'] = clases_secas\n",
    "\n",
    "char_to_num = {'CuNi1':'0','CuNi2':'1','CuNi3':'2'}\n",
    "\n",
    "df_secas['label'].replace(char_to_num,inplace=True)\n",
    "\n",
    "## Recolver dataframe\n",
    "df_secas = df_secas.sample(frac=1,random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70448e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establecer el porcentaje de separación\n",
    "thold1 = int(np.ceil(0.8 * len(df_secas[df_secas.label=='0'])))\n",
    "thold2 = int(np.ceil(0.8 * len(df_secas[df_secas.label=='1'])))\n",
    "thold3 = int(np.ceil(0.8 * len(df_secas[df_secas.label=='2'])))\n",
    "\n",
    "## Separar por clases para entrenamiento\n",
    "train_cu1 = df_secas[df_secas.label == '0'][0:thold1]\n",
    "train_cu2 = df_secas[df_secas.label == '1'][0:thold2]\n",
    "train_cu3 = df_secas[df_secas.label == '2'][0:thold3]\n",
    "\n",
    "## tomar las demás imágenes para test\n",
    "test_cu1 = df_secas[df_secas.label == '0'][thold1:]\n",
    "test_cu2 = df_secas[df_secas.label == '1'][thold2:]\n",
    "test_cu3 = df_secas[df_secas.label == '2'][thold3:]\n",
    "\n",
    "\n",
    "## Constuir un solo dataset de training\n",
    "train_df =  pd.concat([pd.concat([train_cu1,train_cu2]),train_cu3])\n",
    "\n",
    "## Construir un solo dataset de test\n",
    "test_df = pd.concat([pd.concat([test_cu1,test_cu2]),test_cu3])\n",
    "\n",
    "## Cantidad de muestras por clase\n",
    "print('Clase MF1: train: ',len(train_cu1),', test: ',len(test_cu1))\n",
    "print('Clase MF2: train: ',len(train_cu2),', test: ',len(test_cu2))\n",
    "print('Clase MF3: train: ',len(train_cu3),', test: ',len(test_cu3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crear objetos transformadores\n",
    "## Para entrenamiento\n",
    "img_generator_training = tf.keras.preprocessing.image.ImageDataGenerator(  \n",
    "    rescale=1./255,      \n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "## Crear objeto generador de imágenes a partir del objeto transformator\n",
    "## Pra entrenamiento\n",
    "train_generator= img_generator_training.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    #directory=\"./train/\",\n",
    "    x_col=\"routes\",\n",
    "    y_col=\"label\",\n",
    "    labels = ['MF1','MF2','MF3'],\n",
    "    subset=\"training\",\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"sparse\" ,\n",
    "    validation_split=0.2,\n",
    "    color_mode =\"grayscale\",\n",
    "    target_size=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ab05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_secas_expanded = []\n",
    "y_train_secas_expanded = []\n",
    "\n",
    "batches = 50\n",
    "cnt = 0\n",
    "\n",
    "for i in range(batches):\n",
    "    \n",
    "    x,y = train_generator.next()\n",
    "\n",
    "    X_train_secas_expanded.extend(x)\n",
    "    y_train_secas_expanded.extend(y)\n",
    "    \n",
    "print(np.shape(X_train_secas_expanded),np.shape(y_train_secas_expanded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db762b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train_secas_expanded[0],cmap='gray')\n",
    "print(np.shape(X_train_secas_expanded[0]))\n",
    "print(np.min(X_train_secas_expanded[0]),np.max(X_train_secas_expanded[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aff5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset de prueba\n",
    "test_df = test_df.sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "\n",
    "X_test_secas = []\n",
    "y_test_secas = []\n",
    "\n",
    "nsize = 128\n",
    "\n",
    "## Recorrerr rutas\n",
    "for i in range(len(test_df)):\n",
    "    \n",
    "    #Capturar ruta y label\n",
    "    ruta = test_df.iloc[i].routes\n",
    "    label = test_df.iloc[i].label\n",
    "    \n",
    "    ##cargar imagen\n",
    "    im = tf.keras.preprocessing.image.load_img(ruta,color_mode='grayscale')\n",
    "    \n",
    "    X_test_secas.append(tf.keras.preprocessing.image.img_to_array(im.resize((nsize,nsize))))\n",
    "    y_test_secas.append(test_df.iloc[i].label)\n",
    "    \n",
    "print('Test: train->',np.shape(X_test_secas),' test ->',np.shape(y_test_secas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5841609",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_secas_expanded = np.array(X_train_secas_expanded)\n",
    "x_test_secas = np.array(X_test_secas)\n",
    "\n",
    "x_train_secas_expanded = x_train_secas_expanded.astype('float32')\n",
    "x_test_secas= x_test_secas.astype('float32')\n",
    " \n",
    "y_test_secas = tf.keras.utils.to_categorical(y_test_secas)\n",
    "#y_train_expanded = tf.keras.utils.to_categorical(y_train_expanded) \n",
    "\n",
    "#x_train_expanded /= 255\n",
    "x_test_secas /= 255\n",
    "\n",
    "print('x_train shape:', x_train_secas_expanded.shape)\n",
    "print('Number of images in x_train', x_train_secas_expanded.shape[0], \"y_train:\", np.shape(y_train_secas_expanded))\n",
    "print('Number of images in x_test', x_test_secas.shape, \"y_test: \", np.shape(y_test_secas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b8ed2",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656eaa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder_block(layers.Layer):\n",
    "    \n",
    "    ## Inicializar la clase de capa convolucional\n",
    "    def __init__(self,out_channels,kernel_size=(3, 3)):\n",
    "        ## conv y bn son las dos capas (que contienen pesos) del bloque/clase\n",
    "        super(encoder_block, self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channels,kernel_size, activation='relu', padding='same')\n",
    "        self.pooling = layers.MaxPooling2D()\n",
    "        self.bn = layers.BatchNormalization()       \n",
    "    \n",
    "    \n",
    "    ## The call method is the same as the forward method of the block\n",
    "    def call(self, input_tensor,training = False):\n",
    "        x = self.conv(input_tensor)\n",
    "        x = self.pooling(x)\n",
    "        x = self.bn(x,training = training)           \n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "class Encoder(keras.Model):\n",
    "    \n",
    "    def __init__(self,name = 'encoder',n_dims=128,**kwargs):\n",
    "        super(Encoder, self).__init__(name=name, **kwargs)         \n",
    "        ## Bloque convolucional:\n",
    "        self.block1 = encoder_block(512)\n",
    "        self.block2 = encoder_block(256)\n",
    "        self.block3 = encoder_block(128)\n",
    "        self.block4 = encoder_block(64)\n",
    "        self.flattening = layers.Flatten()\n",
    "        self.z_mean = layers.Dense(n_dims,activation = 'relu')\n",
    "        self.z_logvar = layers.Dense(n_dims,activation = 'relu')\n",
    "        self.embedding = Sampling()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def call(self, tensor_input):\n",
    "        x = self.block1(tensor_input)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.flattening(x)\n",
    "        mu = self.z_mean(x)\n",
    "        logvar = self.z_logvar(x)\n",
    "        z = self.embedding([mu,logvar])\n",
    "        \n",
    "        \n",
    "        return [mu,logvar,z]\n",
    "    \n",
    "\n",
    "class decoder_block(layers.Layer):\n",
    "    \n",
    "    def __init__(self,out_channels,kernel_size=(3,3)):\n",
    "        super(decoder_block,self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channels,kernel_size, activation='relu', padding='same')\n",
    "        self.bn = layers.BatchNormalization()   \n",
    "        \n",
    "    def call(self,input_tensor,training = False):\n",
    "        x = self.conv(input_tensor)\n",
    "        x = self.bn(x, training = training)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Decoder(keras.Model):\n",
    "    \n",
    "    def __init__(self,name = 'decoder',**kwargs):\n",
    "        super(Decoder, self).__init__(name=name, **kwargs)\n",
    "        self.firts_layer = layers.Dense(8*8*256,activation = 'relu')\n",
    "        self.upsam1 = layers.UpSampling2D(size=(2, 2))  \n",
    "        self.block1 = decoder_block(128)\n",
    "        self.upsam2 = layers.UpSampling2D(size=(2, 2)) \n",
    "        self.block2 = decoder_block(64)\n",
    "        self.upsam3 = layers.UpSampling2D(size=(4, 4)) \n",
    "        self.block3 = decoder_block(32)        \n",
    "        self.conv = layers.Conv2D(16, (3, 3), activation='relu', padding='same')\n",
    "        self.final = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')    \n",
    "        \n",
    "        \n",
    "    def call(self, embedding_input):\n",
    "        embedding_input = self.firts_layer(embedding_input)\n",
    "        x = tf.reshape(embedding_input,[-1,8,8,256])\n",
    "        x = self.upsam1(x)\n",
    "        x = self.block1(x)       \n",
    "        x = self.upsam2(x)\n",
    "        x = self.block2(x) \n",
    "        x = self.upsam3(x)\n",
    "        x = self.block3(x)        \n",
    "        x = self.conv(x)\n",
    "        out = self.final(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self,encoder,decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        ##Variables que guardan paso a paso las pérdidas\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name='kl_loss')        \n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name='reconstruction_loss')\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return[\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def train_step(self,data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            ## Generar embebidos\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            \n",
    "            ## Reconstruir embebidos\n",
    "            reconstruction = self.decoder(z)\n",
    "            \n",
    "            ## Normalizar reconstrucciones\n",
    "            #reconstruction /= tf.reduce_max(reconstruction)\n",
    "            \n",
    "            ## Calcular la diferencia binaria entre las imágenes de entrada y las reconstrucciones\n",
    "            \n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                    tf.reduce_sum(\n",
    "                        keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                    )\n",
    "                )            \n",
    "            \n",
    "            '''\n",
    "            reconstruction_loss =tf.reduce_mean(\n",
    "                tf.reduce_sum( tf.keras.losses.MeanSquaredError()(data, reconstruction)\n",
    "                             )\n",
    "            )\n",
    "            '''\n",
    "            \n",
    "            ## Pérdida de kullback leibler\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))            \n",
    "        \n",
    "            ## Pérdida total\n",
    "            total_loss = reconstruction_loss + kl_loss     \n",
    "            \n",
    "            ## Calcular los gradientes \n",
    "            grads = tape.gradient(total_loss, self.trainable_weights)       \n",
    "            \n",
    "            ## Guardar reconstrucciones en una variable propia del modelo\n",
    "            self.reconstruction = reconstruction\n",
    "            \n",
    "            ## Calcular gradientes entre los pesos            \n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "            \n",
    "            ## Actualizar la variable de pérdida total\n",
    "            self.total_loss_tracker.update_state(total_loss)\n",
    "            \n",
    "            ## Actualizar la variable de pérdida de reconstrucción\n",
    "            self.reconstruction_loss_tracker.update_state(reconstruction_loss)       \n",
    "            \n",
    "            ## Actualizar la variable de pérdida por kull-back\n",
    "            self.kl_loss_tracker.update_state(kl_loss)       \n",
    "            \n",
    "            return {\n",
    "                \"loss\": self.total_loss_tracker.result(),\n",
    "                \"reconstruction_loss\": self.reconstruction_loss_tracker.result(), \n",
    "                'kl_loss':self.kl_loss_tracker.result(),\n",
    "            }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d910744",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder()\n",
    "dec = Decoder()\n",
    "\n",
    "vae = VAE(enc,dec)\n",
    "\n",
    "opt = tf.optimizers.Adam(learning_rate = 0.00001)\n",
    "#nll = lambda x , rv_x: -rv_x.log_prob(x)\n",
    "vae.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "vae.fit(x_train_secas_expanded, epochs=2000, \n",
    "                batch_size=16,\n",
    "                         callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Guardar modelo\n",
    "vae.encoder.save('models/sub_2_vae_encoder_dry_128',save_format=\"tf\")\n",
    "vae.decoder.save('models/sub_2_vae_decoder_dry_128',save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_encoder = keras.models.load_model('Gaussian_vae/Models/GVAE_encoder_dry_128')\n",
    "vae_decoder = keras.models.load_model('Gaussian_vae/Models/GVAE_decoder_dry_128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53466d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo = 'secas'\n",
    "if tipo == 'secas': \n",
    "    print('Dataset secas')\n",
    "    data_train = x_train_secas_expanded\n",
    "    data_test = x_test_secas\n",
    "\n",
    "    label_train = y_train_secas_expanded\n",
    "    label_test = y_test_secas\n",
    "else:\n",
    "    print('Dataset humedas')\n",
    "    data_train = x_train_humedas\n",
    "    data_test = x_test_humedas\n",
    "\n",
    "    label_train = y_train_humedas\n",
    "    label_test = y_test_humedas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ca6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embebidos del encoder\n",
    "encoder_embds  = vae_encoder.predict(data_train)\n",
    "print('Shape_embs: ',np.shape(encoder_embds))\n",
    "\n",
    "# Embebidos del encoder\n",
    "encoder_embds_test  = vae_encoder.predict(data_test)\n",
    "print('Shape_embs: ',np.shape(encoder_embds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7888ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Media = 0, Varianza = 1, Z = 2\n",
    "D = 2\n",
    "\n",
    "## Dimensiones\n",
    "dmx = 16\n",
    "dmy = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ebaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(encoder_embds[D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imágenes del Decoder (from encoder embeddings)\n",
    "autoencoder_imgs = vae_decoder.predict(encoder_embds[D])\n",
    "print(np.shape(autoencoder_imgs),np.shape(encoder_embds[D]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633d7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(encoder_embds[D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 4))\n",
    "for i in range(6):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, 20, i + 1)\n",
    "    plt.imshow(data_train[i].reshape(128,128,1))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)   \n",
    "    \n",
    "    # display encoded image\n",
    "    ax = plt.subplot(3, 20, i + 1 + 20)\n",
    "    plt.imshow(encoder_embds[D][i].reshape(dmy,dmx),cmap='jet')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, 20, 2*20 +i+ 1)\n",
    "    plt.imshow(autoencoder_imgs[i].reshape(128,128,1))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5803c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imágenes del Decoder (from encoder embeddings)\n",
    "autoencoder_imgs_test = vae_decoder.predict(encoder_embds_test[D])\n",
    "print(np.shape(autoencoder_imgs_test),np.shape(encoder_embds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae083f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 4))\n",
    "for i in range(6):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, 20, i + 1)\n",
    "    plt.imshow(data_test[i].reshape(128,128,1))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)   \n",
    "    \n",
    "    # display encoded image\n",
    "    ax = plt.subplot(3, 20, i + 1 + 20)\n",
    "    plt.imshow(encoder_embds_test[D][i].reshape(dmy,dmx),cmap='jet')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, 20, 2*20 +i+ 1)\n",
    "    plt.imshow(autoencoder_imgs_test[i].reshape(128,128,1))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd32daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data = PCA(n_components=2)\n",
    "PCA_2dim = pca_data.fit_transform(encoder_embds[D])\n",
    "PCA_2dim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74736c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_text = pd.DataFrame(label_train).replace({0: \"MF1\", 1: \"MF2\",2: \"MF3\"})\n",
    "labels_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1352ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_img = pd.DataFrame()                 \n",
    "data_img['x'] = PCA_2dim[:,0]\n",
    "data_img['y'] = PCA_2dim[:,1]\n",
    "data_img['label'] = pd.DataFrame(labels_text)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.scatterplot(x=data_img.x,y=data_img.y,hue='label',data=data_img, style='label',\n",
    "            sizes=(60, 100), alpha=0.4, palette={\"MF3\": \"red\", \"MF2\": \"green\", \"MF1\": \"blue\"},\n",
    "                legend=True)\n",
    "plt.xlabel(' ')\n",
    "plt.ylabel(' ')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "#plt.legend(fontsize=\"18\")\n",
    "#plt.xticks(range(-5, 5))\n",
    "#plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047c3e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_text_test = pd.DataFrame(np.argmax(label_test,axis=1)).replace({0: \"MF1\", 1: \"MF2\",2: \"MF3\"})\n",
    "labels_text_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c382f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data_test = PCA(n_components=2)\n",
    "PCA_2dim_test = pca_data_test.fit_transform(encoder_embds_test[D])\n",
    "PCA_2dim_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1a82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_img_pca_test = pd.DataFrame()                 \n",
    "data_img_pca_test['x'] = PCA_2dim_test[:,0]\n",
    "data_img_pca_test['y'] = PCA_2dim_test[:,1]\n",
    "data_img_pca_test['label'] = pd.DataFrame(labels_text_test)\n",
    "\n",
    "\n",
    "sctter = plt.figure(figsize=(15,5))\n",
    "sns.scatterplot(x=data_img_pca_test.x,y=data_img_pca_test.y,hue='label',data=data_img_pca_test,style='label',\n",
    "            sizes=(60, 100), alpha=1, palette={\"MF3\": \"red\", \"MF2\": \"green\", \"MF1\": \"blue\"},\n",
    "                legend=True)\n",
    "plt.xlabel(' ')\n",
    "plt.ylabel(' ')\n",
    "#plt.xticks([])\n",
    "#plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3519acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
