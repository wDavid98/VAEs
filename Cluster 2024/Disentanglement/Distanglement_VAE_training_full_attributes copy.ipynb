{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "## Uso de GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] =  \"0\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "## Librerías\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import cv2 as cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import gc\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes secas: 0\n",
      "MF1: 0\n",
      "MF2: 0\n",
      "MF3: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2305896/1912415092.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  routes_dataset['label'].replace(char_to_num,inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>route_image</th>\n",
       "      <th>label</th>\n",
       "      <th>number</th>\n",
       "      <th>route_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, route_image, label, number, route_mask]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Obtener todas las rutas de las imágenes en el dataset\n",
    "ruta = '../../../../../../data/Materiales/Micrografías segmentaciones/secas/*/*/*/*.jpg'\n",
    "rutas_dataset  = glob.glob('../../../../../../data/Materiales/Micrografías segmentaciones/secas/*/*/*/*.jpg')\n",
    "\n",
    "## Separar rutas\n",
    "mask_list = []\n",
    "image_list = []\n",
    "for ruta in rutas_dataset:    \n",
    "    ruta_list = ruta.split('/')       \n",
    "    clase = ruta_list[6]\n",
    "    number = ruta_list[7]\n",
    "    tipo = ruta_list[8]\n",
    "    name = ruta_list[9].split('.')[0]\n",
    "    \n",
    "    if tipo == 'train':\n",
    "        image_list.append([name,ruta,clase,number])\n",
    "    elif tipo == 'mask_bin':\n",
    "        mask_list.append([name,ruta,clase,number])\n",
    "    else:\n",
    "        None\n",
    "\n",
    "mask_pd = pd.DataFrame(mask_list,columns=['name','route_mask','label','number']).sort_values(by='name')\n",
    "image_pd = pd.DataFrame(image_list,columns=['name','route_image','label','number']).sort_values(by='name')\n",
    "\n",
    "routes_dataset = image_pd.merge(mask_pd,on=['name','label','number'],how='left')\n",
    "\n",
    "routes_dataset.dropna(inplace=True)\n",
    "\n",
    "routes_dataset = routes_dataset.sample(frac = 1)\n",
    "\n",
    "print('Imágenes secas:', np.shape(routes_dataset)[0])\n",
    "print('MF1:', np.shape(routes_dataset[routes_dataset['label']=='MF1'])[0])\n",
    "print('MF2:', np.shape(routes_dataset[routes_dataset['label']=='MF2'])[0])\n",
    "print('MF3:', np.shape(routes_dataset[routes_dataset['label']=='MF3'])[0])\n",
    "\n",
    "char_to_num = {'MF1':'0','MF2':'1','MF3':'2'}\n",
    "\n",
    "routes_dataset['label'].replace(char_to_num,inplace=True)\n",
    "\n",
    "routes_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establecer el porcentaje de separación\n",
    "thold1 = int(np.ceil(0.8 * len(routes_dataset[routes_dataset.label=='0'])))\n",
    "thold2 = int(np.ceil(0.8 * len(routes_dataset[routes_dataset.label=='1'])))\n",
    "thold3 = int(np.ceil(0.8 * len(routes_dataset[routes_dataset.label=='2'])))\n",
    "\n",
    "## Separar por clases para entrenamiento\n",
    "train_cu1 = routes_dataset[routes_dataset.label == '0'][0:thold1]\n",
    "train_cu2 = routes_dataset[routes_dataset.label == '1'][0:thold2]\n",
    "train_cu3 = routes_dataset[routes_dataset.label == '2'][0:thold3]\n",
    "\n",
    "## tomar las demás imágenes para test\n",
    "test_cu1 = routes_dataset[routes_dataset.label == '0'][thold1:]\n",
    "test_cu2 = routes_dataset[routes_dataset.label == '1'][thold2:]\n",
    "test_cu3 = routes_dataset[routes_dataset.label == '2'][thold3:]\n",
    "\n",
    "\n",
    "## Constuir un solo dataset de training\n",
    "train_df =  pd.concat([pd.concat([train_cu1,train_cu2]),train_cu3]).sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "\n",
    "## Construir un solo dataset de test\n",
    "test_df = pd.concat([pd.concat([test_cu1,test_cu2]),test_cu3]).sample(frac=1,random_state=100).reset_index(drop=True)\n",
    "\n",
    "## Cantidad de muestras por clase\n",
    "print('Clase MF1: train: ',len(train_cu1),', test: ',len(test_cu1))\n",
    "print('Clase MF2: train: ',len(train_cu2),', test: ',len(test_cu2))\n",
    "print('Clase MF3: train: ',len(train_cu3),', test: ',len(test_cu3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to get contours and features\n",
    "def get_contours_and_features(binary_map):\n",
    "    #https://docs.opencv.org/4.x/d3/d05/tutorial_py_table_of_contents_contours.html\n",
    "    binary_map = cv2.cvtColor(binary_map, cv2.COLOR_BGR2GRAY)\n",
    "    contours, hierarchy = cv2.findContours(binary_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contours_features = []\n",
    "    for contour in contours:\n",
    "        error = 1e-5\n",
    "        moments = cv2.moments(contour)\n",
    "        cx = moments['m10'] / (moments['m00'] + error)\n",
    "        cy = moments['m01'] / (moments['m00'] + error)\n",
    "        center_of_mass = [cx, cy]\n",
    "        x,y,w,h = cv2.boundingRect(contour)        \n",
    "        rect_area = w*h\n",
    "        features = {\n",
    "            'bounding_box': (x,y,w,h),\n",
    "            'area': cv2.contourArea(contour),\n",
    "            'perimeter': cv2.arcLength(contour, True),       \n",
    "            #'solidity': np.float32(cv2.contourArea(contour))/cv2.convexHull(contour),\n",
    "            'equivalent_diameter': np.sqrt(4*cv2.contourArea(contour)/np.pi),            \n",
    "            'moments': moments,\n",
    "            'center_of_mass': center_of_mass,\n",
    "            'contour': contour\n",
    "        }\n",
    "        contours_features.append(features)\n",
    "        del features\n",
    "    #plt.imshow(contours_map, cmap='gray')\n",
    "    return contours_features\n",
    "\n",
    "# function to get a determined property from a list of contours features (area by default)\n",
    "def get_item(contour_features, key='area'):\n",
    "    areas = []\n",
    "    for contour_feature in contour_features:\n",
    "        area =  contour_feature[key]\n",
    "        areas.append(area)\n",
    "    return areas\n",
    "\n",
    "# function to get tensor of one image\n",
    "def load_image(file_name):\n",
    "  raw = tf.io.read_file(file_name)\n",
    "  tensor = tf.io.decode_jpeg(raw,channels=1)\n",
    "  tensor = tf.image.resize(tensor, [128,128])\n",
    "  tensor = tf.cast(tensor, tf.float32) / 255.0\n",
    "  return tensor\n",
    "\n",
    "# function to get set of binary image from image loaded\n",
    "def get_binary_image(filenames):\n",
    "    tensores = []\n",
    "    for filename in filenames:\n",
    "        raw = tf.io.read_file(filename)\n",
    "        tensor = tf.io.decode_jpeg(raw,channels=3)\n",
    "        tensor = tf.image.resize(tensor, [128,128])\n",
    "        tensor = tf.cast(tensor, tf.float32) / 255.0\n",
    "        tensores.append(tensor)\n",
    "    return tensores\n",
    "\n",
    "def get_geometric_atributes(binary_images):\n",
    "    descriptors = []\n",
    "    for binary_img in binary_images:\n",
    "        ## Formato\n",
    "        image = binary_img.numpy().astype(np.uint8)       \n",
    "        \n",
    "        ## Capturar contornos\n",
    "        contour_features = get_contours_and_features(image)\n",
    "        \n",
    "        ## Calcular vector de áreas de poro (todos los poros)\n",
    "        areas = get_item(contour_features, key='area')\n",
    "\n",
    "        ## Calcular vector de perímetros de poro (todo los poros)\n",
    "        pmtro = get_item(contour_features, key='perimeter')\n",
    "\n",
    "        ## Calcular el diametro equivalente de los poros\n",
    "        eq_diameter = get_item(contour_features, key='equivalent_diameter')           \n",
    "\n",
    "        ## Número de poros\n",
    "        npores = np.shape(areas)[0]\n",
    "\n",
    "        descriptor = [np.mean(areas), np.mean(pmtro),np.mean(eq_diameter), npores]\n",
    "        \n",
    "        descriptors.append(descriptor)\n",
    "        \n",
    "    \n",
    "    return descriptors\n",
    "\n",
    "def create_dataset(buffer,file_names, labels, file_mask): \n",
    "  ## Get binary images   \n",
    "  masks = get_binary_image(file_mask)\n",
    "  ## Get geometric atributes from binary images\n",
    "  attributes = get_geometric_atributes(masks)\n",
    "  ## Create dataset from tensors assosiated with labels and attributes\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((file_names,labels,attributes))\n",
    "  ## Shuffle dataset\n",
    "  dataset.shuffle(buffer_size=buffer)\n",
    "  ## Map dataset to load images (a = image, b = label, c = attributes, d = mask)\n",
    "  dataset = dataset.map(lambda file_name, label, attributes : (load_image(file_name), label, attributes))\n",
    "\n",
    "  return dataset\n",
    "\n",
    "file_names = train_df['route_image'].to_numpy()\n",
    "file_mask = train_df['route_mask'].to_numpy()\n",
    "labels = train_df['label'].to_numpy()\n",
    "## Create training dataset using tf.data of 16 images\n",
    "dataset = create_dataset(16,file_names, labels,file_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for i in dataset.batch(16):\n",
    "    a = i[0]\n",
    "    b = i[1]\n",
    "    c = i[2]\n",
    "    #d = i[3]\n",
    "\n",
    "n =  0\n",
    "print(c[n].numpy())\n",
    "print(b[n].numpy())\n",
    "plt.imshow(a[n],cmap='gray')\n",
    "#plt.imshow(d[n],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder convencional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")        \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            \n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data[0])\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction /= tf.reduce_max(reconstruction)\n",
    "            \n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data[0], reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            '''\n",
    "            reconstruction_loss =tf.reduce_mean(\n",
    "                tf.reduce_sum( tf.keras.losses.MeanSquaredError()(data, reconstruction)\n",
    "                             )\n",
    "            )\n",
    "            '''\n",
    "            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))            \n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.reconstruction = reconstruction\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)       \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###_____________________________ENCODER________________________##\n",
    "latent_dim = 16\n",
    "\n",
    "nx, ny = 128, 128\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(nx, ny,1))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same',name='layer_E1')(encoder_inputs)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same',name='layer_E2')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',name='layer_E3')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same',name='layer_E4')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_E6')(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(inputs=encoder_inputs, outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entrada Z\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "##dimensiones\n",
    "ndim = 16\n",
    "nfilts = 128\n",
    "\n",
    "## anti-flatten de la última capa convolucional\n",
    "x = layers.Dense(ndim * ndim * nfilts, activation=\"relu\")(latent_inputs)\n",
    "\n",
    "## Reshape para reconstruir la última convolucional\n",
    "x = layers.Reshape((ndim,ndim, nfilts))(x)\n",
    "\n",
    "## Capas convolucionales\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_D1')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_D2')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same',name='layer_D4')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same',name='layer_D6')(x)\n",
    "\n",
    "decoder_outputs = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same',name='layer_D7')(x)\n",
    "\n",
    "## Construcción del decoder\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "opt = tf.optimizers.Adam(learning_rate = 0.000001)\n",
    "#nll = lambda x , rv_x: -rv_x.log_prob(x)\n",
    "vae.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "vae.fit(dataset.batch(16), epochs=2000, \n",
    "                batch_size=16,\n",
    "                         callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Guardar modelo https://www.tensorflow.org/guide/saved_model?hl=es-419\n",
    "vae.encoder.save('Models2/GVAE_encoder_DRY_1_16.h5')\n",
    "vae.decoder.save('Models2/GVAE_decoder_DRY_1_16.h5')\n",
    "\n",
    "del vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disentangled variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, regressor, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.regressor_area = regressor\n",
    "        self.regressor_perimeter = regressor\n",
    "        self.regressor_eq_diameter = regressor\n",
    "        self.regressor_nporos = regressor\n",
    "        ## loss_tracker\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")        \n",
    "        self.estimation_area_loss_tracker = keras.metrics.Mean(name=\"estimation_area_loss\")\n",
    "        self.estimation_perimeter_loss_tracker = keras.metrics.Mean(name=\"estimation_perimeter_loss\")\n",
    "        self.estimation_eq_diameter_loss_tracker = keras.metrics.Mean(name=\"estimation_eq_diameter_loss\")\n",
    "        self.estimation_nporos_loss_tracker = keras.metrics.Mean(name=\"estimation_nporos_loss\")\n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.estimation_area_loss_tracker,\n",
    "            self.estimation_perimeter_loss_tracker,\n",
    "            self.estimation_eq_diameter_loss_tracker,\n",
    "            self.estimation_nporos_loss_tracker           \n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            ## Valores estimados por el encoder\n",
    "            z_mean, z_log_var, z = self.encoder(data[0])\n",
    "            \n",
    "            ## Valores geométricos asociados a los datos\n",
    "            geometrics_features = data[2]\n",
    "\n",
    "            ## Reconstrucción del embebido del encoder\n",
    "            reconstruction = self.decoder(z)            \n",
    "\n",
    "            ## Reducción de la reconstrucción\n",
    "            reconstruction /= tf.reduce_max(reconstruction)\n",
    "\n",
    "            ## Valores estimados apartir del regresor            \n",
    "            area_estimation = self.regressor_area(z)\n",
    "            perimeter_estimation = self.regressor_perimeter(z)\n",
    "            eq_diameter_estimation = self.regressor_eq_diameter(z)\n",
    "            nporos_estimation = self.regressor_nporos(z)\n",
    "            \n",
    "            ## Error de area RMSE\n",
    "            area_loss = tf.reduce_mean(tf.keras.losses.MeanSquaredError()(geometrics_features[:,0], area_estimation))\n",
    "            ## Error de perímetro RMSE\n",
    "            perimeter_loss = tf.reduce_mean(tf.keras.losses.MeanSquaredError()(geometrics_features[:,1], perimeter_estimation))\n",
    "            ## Error de diámetro equivalente RMSE\n",
    "            eq_diameter_loss = tf.reduce_mean(tf.keras.losses.MeanSquaredError()(geometrics_features[:,2], eq_diameter_estimation))\n",
    "            ## Error de número de poros RMSE\n",
    "            nporos_loss = tf.reduce_mean(tf.keras.losses.MeanSquaredError()(geometrics_features[:,3], nporos_estimation))         \n",
    "                                   \n",
    "            \n",
    "            ## Error de reconstrucción\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data[0], reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            '''\n",
    "            reconstruction_loss =tf.reduce_mean(\n",
    "                tf.reduce_sum( tf.keras.losses.MeanSquaredError()(data, reconstruction)\n",
    "                             )\n",
    "            )\n",
    "            '''           \n",
    "                       \n",
    "            \n",
    "            ## Error de divergencia KL\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))   \n",
    "\n",
    "            ## Error total          \n",
    "            total_loss = reconstruction_loss + kl_loss + area_loss + perimeter_loss + eq_diameter_loss + nporos_loss\n",
    "        \n",
    "        ## Actualización de los gradientes\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "\n",
    "        ## Actualización de lA RECONSTRUCCIÓN\n",
    "        self.reconstruction = reconstruction\n",
    "\n",
    "        ### Actualización de los pesos\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)   \n",
    "        self.estimation_area_loss_tracker.update_state(area_loss)\n",
    "        self.estimation_perimeter_loss_tracker.update_state(perimeter_loss)\n",
    "        self.estimation_eq_diameter_loss_tracker.update_state(eq_diameter_loss)\n",
    "        self.estimation_nporos_loss_tracker.update_state(nporos_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(), \n",
    "            \"Area_Error\": self.estimation_area_loss_tracker.result(),\n",
    "            \"Perimeter_Error\": self.estimation_perimeter_loss_tracker.result(),\n",
    "            \"Eq_Diameter_Error\": self.estimation_eq_diameter_loss_tracker.result(),\n",
    "            \"Nporos_Error\": self.estimation_nporos_loss_tracker.result()        \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###_____________________________ENCODER________________________##\n",
    "latent_dim = 16\n",
    "\n",
    "nx, ny = 128, 128\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(nx, ny,1))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same',name='layer_E1')(encoder_inputs)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same',name='layer_E2')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',name='layer_E3')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_E4')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_E6')(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(inputs=encoder_inputs, outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entrada Z\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "##dimensiones\n",
    "ndim = 16\n",
    "nfilts = 128\n",
    "\n",
    "## anti-flatten de la última capa convolucional\n",
    "x = layers.Dense(ndim * ndim * nfilts, activation=\"relu\")(latent_inputs)\n",
    "\n",
    "## Reshape para reconstruir la última convolucional\n",
    "x = layers.Reshape((ndim,ndim, nfilts))(x)\n",
    "\n",
    "## Capas convolucionales\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_D1')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_D2')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same',name='layer_D4')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same',name='layer_D6')(x)\n",
    "\n",
    "decoder_outputs = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same',name='layer_D7')(x)\n",
    "\n",
    "## Construcción del decoder\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Estimador de un único valor geométrico\n",
    "\n",
    "## Input layer for regressor model of 16-dim vector input\n",
    "regressor_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "## Hidden dense layer\n",
    "x = layers.Dense(8, activation='relu')(regressor_inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Dense(4, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Dense(2, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "## Output layer\n",
    "regressor_output_feature = layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "\n",
    "## regressor model\n",
    "regressor = keras.Model(regressor_inputs, regressor_output_feature, name=\"regressor\")\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder,regressor)\n",
    "opt = tf.optimizers.Adam(learning_rate = 0.000001)\n",
    "#nll = lambda x , rv_x: -rv_x.log_prob(x)\n",
    "vae.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "vae.fit(dataset.batch(16), epochs=2000, \n",
    "                batch_size=16,\n",
    "                         callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=45)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Guardar modelohttps://www.tensorflow.org/guide/saved_model?hl=es-419\n",
    "## crear carpeta dentro de models para guardar los modelos si no existe\n",
    "name_new_folder = 'MULTI_regressor_1'\n",
    "if not os.path.exists('Models2/'+name_new_folder):\n",
    "    os.makedirs('Models2/'+name_new_folder)\n",
    "    vae.encoder.save('Models2/'+name_new_folder+'/dist_GVAE_encoder_1_16.h5')\n",
    "    vae.decoder.save('Models2/'+name_new_folder+'/dist_GVAE_decoder_1_16.h5')\n",
    "    vae.regressor_area.save('Models2/'+name_new_folder+'/dist_GVAE_regressor_area_1_16.h5')\n",
    "    vae.regressor_perimeter.save('Models2/'+name_new_folder+'/dist_GVAE_regressor_perimeter_1_16.h5')\n",
    "    vae.regressor_eq_diameter.save('Models2/'+name_new_folder+'/dist_GVAE_regressor_eq_diameter_1_16.h5')\n",
    "    vae.regressor_nporos.save('Models2/'+name_new_folder+'/dist_GVAE_regressor_nporos_1_16.h5')    \n",
    "else:\n",
    "    vae.encoder.save('Models2/'+name_new_folder+'/dist_GVAE_encoder_1_16.h5')\n",
    "    vae.decoder.save('Models2/'+name_new_folder+'/dist_GVAE_decoder_1_16.h5')\n",
    "    vae.regressor_area.save('Models2/'+name_new_folder+'/dist_GVAE_regressor_area_1_16.h5')\n",
    "    vae.regressor_perimeter.save('Models2/'+name_new_folder+'/dist_GVAE_regressor_perimeter_1_16.h5')\n",
    "    vae.regressor_eq_diameter.save('Models2/'+name_new_folder+'/dist_GVAE_regressor_eq_diameter_1_16.h5')\n",
    "    vae.regressor_nporos.save('Models2/'+name_new_folder+'/dist_GVAE_regressor_nporos_1_16.h5')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
