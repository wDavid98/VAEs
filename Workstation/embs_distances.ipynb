{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] =  \"0\"\n",
    "\n",
    "## Uso de GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "\n",
    "\n",
    "## Librerías\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import cv2 as cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import gc\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtener todas las rutas de las imágenes en el dataset\n",
    "ruta = '../Datasets/Micrografías_segmentadas/secas/*/*/*/*.jpg'\n",
    "rutas_dataset  = glob.glob('../../../Datasets/Micrografías segmentaciones/secas/*/*/*/*.jpg')\n",
    "\n",
    "## Separar rutas\n",
    "mask_list = []\n",
    "image_list = []\n",
    "for ruta in rutas_dataset:    \n",
    "    ruta_list = ruta.split('/')       \n",
    "    clase = ruta_list[6]\n",
    "    number = ruta_list[7]\n",
    "    tipo = ruta_list[8]\n",
    "    name = ruta_list[9].split('.')[0]\n",
    "    \n",
    "    if tipo == 'train':\n",
    "        image_list.append([name,ruta,clase,number])\n",
    "    elif tipo == 'mask_bin':\n",
    "        mask_list.append([name,ruta,clase,number])\n",
    "    else:\n",
    "        None\n",
    "\n",
    "mask_pd = pd.DataFrame(mask_list,columns=['name','route_mask','label','number']).sort_values(by='name')\n",
    "image_pd = pd.DataFrame(image_list,columns=['name','route_image','label','number']).sort_values(by='name')\n",
    "\n",
    "routes_dataset = image_pd.merge(mask_pd,on=['name','label','number'],how='left')\n",
    "\n",
    "routes_dataset.dropna(inplace=True)\n",
    "\n",
    "routes_dataset = routes_dataset.sample(frac = 1)\n",
    "\n",
    "print('Imágenes secas:', np.shape(routes_dataset)[0])\n",
    "print('MF1:', '- secas: ', np.shape(routes_dataset[routes_dataset['label']=='MF1'])[0])\n",
    "print('MF2:', '- secas: ', np.shape(routes_dataset[routes_dataset['label']=='MF2'])[0])\n",
    "print('MF3:', '- secas: ', np.shape(routes_dataset[routes_dataset['label']=='MF3'])[0])\n",
    "\n",
    "char_to_num = {'MF1':'0','MF2':'1','MF3':'2'}\n",
    "\n",
    "routes_dataset['label'].replace(char_to_num,inplace=True)\n",
    "\n",
    "df_secas = routes_dataset\n",
    "\n",
    "df_secas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establecer el porcentaje de separación\n",
    "thold1 = int(np.ceil(0.8 * len(df_secas[df_secas.label=='0'])))\n",
    "thold2 = int(np.ceil(0.8 * len(df_secas[df_secas.label=='1'])))\n",
    "thold3 = int(np.ceil(0.8 * len(df_secas[df_secas.label=='2'])))\n",
    "\n",
    "## Separar por clases para entrenamiento\n",
    "train_cu1 = df_secas[df_secas.label == '0'][0:thold1]\n",
    "train_cu2 = df_secas[df_secas.label == '1'][0:thold2]\n",
    "train_cu3 = df_secas[df_secas.label == '2'][0:thold3]\n",
    "\n",
    "## tomar las demás imágenes para test\n",
    "test_cu1 = df_secas[df_secas.label == '0'][thold1:]\n",
    "test_cu2 = df_secas[df_secas.label == '1'][thold2:]\n",
    "test_cu3 = df_secas[df_secas.label == '2'][thold3:]\n",
    "\n",
    "\n",
    "## Constuir un solo dataset de training\n",
    "train_df =  pd.concat([pd.concat([train_cu1,train_cu2]),train_cu3]).sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "\n",
    "## Construir un solo dataset de test\n",
    "test_df = pd.concat([pd.concat([test_cu1,test_cu2]),test_cu3]).sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "\n",
    "## Cantidad de muestras por clase\n",
    "print('Clase MF1: train: ',len(train_cu1),', test: ',len(test_cu1))\n",
    "print('Clase MF2: train: ',len(train_cu2),', test: ',len(test_cu2))\n",
    "print('Clase MF3: train: ',len(train_cu3),', test: ',len(test_cu3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours_and_features(binary_map):\n",
    "    #contours_map  = np.zeros_like(binary_map)\n",
    "    binary_map = cv2.cvtColor(binary_map, cv2.COLOR_BGR2GRAY)\n",
    "    contours, hierarchy = cv2.findContours(binary_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    #contours_map = cv2.drawContours(contours_map, contours, -1, 255, 1)\n",
    "    contours_features = []\n",
    "    for contour in contours:\n",
    "        error = 1e-5\n",
    "\n",
    "        moments = cv2.moments(contour)\n",
    "        cx = moments['m10'] / (moments['m00'] + error)\n",
    "        cy = moments['m01'] / (moments['m00'] + error)\n",
    "        center_of_mass = [cx, cy]\n",
    "        features = {\n",
    "            'area': cv2.contourArea(contour),\n",
    "            'perimeter': cv2.arcLength(contour, True),\n",
    "            'moments': moments,\n",
    "            'center_of_mass': center_of_mass,\n",
    "            'contour': contour\n",
    "        }\n",
    "        contours_features.append(features)\n",
    "        del features    \n",
    "    return contours_features\n",
    "\n",
    "def get_item(contour_features, key='area'):\n",
    "    areas = []\n",
    "    for contour_feature in contour_features:\n",
    "        area =  contour_feature[key]\n",
    "        areas.append(area)\n",
    "    return areas\n",
    "\n",
    "def load_image(file_name):\n",
    "  raw = tf.io.read_file(file_name)\n",
    "  tensor = tf.io.decode_jpeg(raw,channels=1)\n",
    "  tensor = tf.image.resize(tensor, [128,128])\n",
    "  tensor = tf.cast(tensor, tf.float32) / 255.0\n",
    "  return tensor\n",
    "\n",
    "def get_binary_image(filenames):\n",
    "    tensores = []\n",
    "    for filename in filenames:\n",
    "        raw = tf.io.read_file(filename)\n",
    "        tensor = tf.io.decode_jpeg(raw,channels=3)\n",
    "        tensor = tf.image.resize(tensor, [128,128])\n",
    "        tensor = tf.cast(tensor, tf.float32) / 255.0\n",
    "        tensores.append(tensor)\n",
    "    return tensores\n",
    "\n",
    "def get_geometric_atributes(binary_images):\n",
    "    atributes = []\n",
    "    for binary_img in binary_images:\n",
    "        ## Formato\n",
    "        image = binary_img.numpy().astype(np.uint8)       \n",
    "        \n",
    "        ## Capturar contornos\n",
    "        contour_features = get_contours_and_features(image)        \n",
    "\n",
    "        ## obtener área de poros\n",
    "        area = np.ceil(np.sum(get_item(contour_features, key='area')))\n",
    "\n",
    "        ## obtener perímetro de poros\n",
    "        perimetro = np.ceil(np.sum(get_item(contour_features, key='perimeter'))\n",
    ")\n",
    "        ## intersticio\n",
    "        area_total = np.ceil(np.shape(image)[0] * np.shape(image)[1])\n",
    "        intersticio = np.ceil(area_total - area)\n",
    "\n",
    "        ## Cantidad de poros\n",
    "        poros = np.shape(contour_features)[0]\n",
    "\n",
    "        #atributes = [area,perimetro,intersticio,poros]\n",
    "        atributes.append([area,perimetro,intersticio,poros])\n",
    "    \n",
    "    return atributes\n",
    "\n",
    "\n",
    "def load_image(file_name):\n",
    "  raw = tf.io.read_file(file_name)\n",
    "  tensor = tf.io.decode_jpeg(raw,channels=1)\n",
    "  tensor = tf.image.resize(tensor, [128,128])\n",
    "  tensor = tf.cast(tensor, tf.float32) / 255.0\n",
    "  print(\"Final shape: \", tensor.shape)\n",
    "  return tensor\n",
    "\n",
    "def create_dataset(buffer,file_names, labels,file_mask):\n",
    "  images = get_binary_image(file_mask)\n",
    "  attributes = get_geometric_atributes(images)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((file_names,labels,attributes ))\n",
    "  dataset.shuffle(buffer_size=buffer)\n",
    "  dataset = dataset.map(lambda file_name, label, attributes : (load_image(file_name), label, attributes ))\n",
    "  \n",
    "  return dataset\n",
    "\n",
    "file_names = train_df['route_image'].to_numpy()\n",
    "file_mask = train_df['route_mask'].to_numpy()\n",
    "labels = train_df['label'].to_numpy()\n",
    "dataset = create_dataset(16,file_names, labels,file_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for i in dataset.batch(16):\n",
    "    a = i[0]\n",
    "    b = i[1]\n",
    "    c = i[2]\n",
    "\n",
    "n =  0\n",
    "print(c[n].numpy())\n",
    "print(b[n].numpy())\n",
    "plt.imshow(a[n],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distancia intra-clase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distancia inter-clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
