{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] =  \"0\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "## Librerías\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import cv2 as cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import gc\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uso de GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rutas de todas las imágenes\n",
    "\n",
    "## Obtener todas las rutas de las imágenes en el dataset\n",
    "ruta_dataset  = glob.glob('../../../Datasets/Humedas_Secas_procesadas/Recortadas/*/*/*/*.jpg')\n",
    "\n",
    "## Capturar solo rutas secas \n",
    "rutas_imagenes_secas = []\n",
    "rutas_imagenes_humedas = []\n",
    "\n",
    "clases_secas= []\n",
    "clases_humedas = []\n",
    "for ruta in ruta_dataset:\n",
    "    if ruta.split('/')[-2] == 'Secas' or ruta.split('/')[-2] == 'Seca':\n",
    "        clases_secas.append(ruta.split('/')[-4])\n",
    "        rutas_imagenes_secas.append(ruta)\n",
    "    else:\n",
    "        clases_humedas.append(ruta.split('/')[-4])\n",
    "        rutas_imagenes_humedas.append(ruta)\n",
    "\n",
    "## Construcción de datasets\n",
    "data_secas = pd.DataFrame({'ruta':rutas_imagenes_secas,'clase':clases_secas})\n",
    "data_humedas = pd.DataFrame({'ruta':rutas_imagenes_humedas,'clase':clases_humedas})\n",
    "\n",
    "## reemplazo de etiquetas}\n",
    "lables_generalization = {'CuNi1':'MF1','CuNi2':'MF2','CuNi3':'MF3'}\n",
    "data_secas.replace(lables_generalization,inplace=True)\n",
    "data_humedas.replace(lables_generalization,inplace=True)\n",
    "\n",
    "## summary    \n",
    "print('Imágenes secas:', np.shape(rutas_imagenes_secas)[0],' - Imágenes Húmedas: ',np.shape(rutas_imagenes_humedas)[0])\n",
    "print('MF1:', '- secas: ', np.shape(data_secas[data_secas['clase']=='MF1'])[0], '- húmedas: ', np.shape(data_humedas[data_humedas['clase']=='MF1'])[0])\n",
    "print('MF2:', '- secas: ', np.shape(data_secas[data_secas['clase']=='MF2'])[0], '- húmedas: ', np.shape(data_humedas[data_humedas['clase']=='MF2'])[0])\n",
    "print('MF3:', '- secas: ', np.shape(data_secas[data_secas['clase']=='MF3'])[0], '- húmedas: ', np.shape(data_humedas[data_humedas['clase']=='MF3'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crear Dataframe\n",
    "df_secas = pd.DataFrame()\n",
    "df_secas['routes'] = rutas_imagenes_secas\n",
    "df_secas['label'] = clases_secas\n",
    "\n",
    "char_to_num = {'CuNi1':'0','CuNi2':'1','CuNi3':'2'}\n",
    "\n",
    "df_secas['label'].replace(char_to_num,inplace=True)\n",
    "\n",
    "## Recolver dataframe\n",
    "df_secas = df_secas.sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "df_secas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establecer el porcentaje de separación\n",
    "thold1 = int(np.ceil(0.8 * len(df_secas[df_secas.label=='0'])))\n",
    "thold2 = int(np.ceil(0.8 * len(df_secas[df_secas.label=='1'])))\n",
    "thold3 = int(np.ceil(0.8 * len(df_secas[df_secas.label=='2'])))\n",
    "\n",
    "## Separar por clases para entrenamiento\n",
    "train_cu1 = df_secas[df_secas.label == '0'][0:thold1]\n",
    "train_cu2 = df_secas[df_secas.label == '1'][0:thold2]\n",
    "train_cu3 = df_secas[df_secas.label == '2'][0:thold3]\n",
    "\n",
    "## tomar las demás imágenes para test\n",
    "test_cu1 = df_secas[df_secas.label == '0'][thold1:]\n",
    "test_cu2 = df_secas[df_secas.label == '1'][thold2:]\n",
    "test_cu3 = df_secas[df_secas.label == '2'][thold3:]\n",
    "\n",
    "\n",
    "## Constuir un solo dataset de training\n",
    "train_df =  pd.concat([pd.concat([train_cu1,train_cu2]),train_cu3]).sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "\n",
    "## Construir un solo dataset de test\n",
    "test_df = pd.concat([pd.concat([test_cu1,test_cu2]),test_cu3]).sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "\n",
    "## Cantidad de muestras por clase\n",
    "print('Clase MF1: train: ',len(train_cu1),', test: ',len(test_cu1))\n",
    "print('Clase MF2: train: ',len(train_cu2),', test: ',len(test_cu2))\n",
    "print('Clase MF3: train: ',len(train_cu3),', test: ',len(test_cu3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_name):\n",
    "  raw = tf.io.read_file(file_name)\n",
    "  tensor = tf.io.decode_jpeg(raw,channels=1)\n",
    "  tensor = tf.image.resize(tensor, [128,128])\n",
    "  tensor = tf.cast(tensor, tf.float32) / 255.0\n",
    "  print(\"Final shape: \", tensor.shape)\n",
    "  return tensor\n",
    "\n",
    "def create_dataset(file_names, labels):\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((file_names,labels))\n",
    "  dataset.shuffle(buffer_size=16)\n",
    "  dataset = dataset.map(lambda file_name, label: (load_image(file_name), label))\n",
    "  \n",
    "  return dataset\n",
    "\n",
    "file_names = train_df['routes'].to_numpy()\n",
    "labels = train_df['label'].to_numpy()\n",
    "dataset = create_dataset(file_names, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for i in dataset.batch(16):\n",
    "    cnt += 1\n",
    "    a = i[0]\n",
    "    b = i[1]\n",
    "\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "plt.imshow(a[0,:,:,0],cmap='gray')\n",
    "print(b)\n",
    "print(cnt)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")        \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            \n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data[0])\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction /= tf.reduce_max(reconstruction)\n",
    "            \n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data[0], reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            '''\n",
    "            reconstruction_loss =tf.reduce_mean(\n",
    "                tf.reduce_sum( tf.keras.losses.MeanSquaredError()(data, reconstruction)\n",
    "                             )\n",
    "            )\n",
    "            '''\n",
    "            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))            \n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.reconstruction = reconstruction\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)       \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###_____________________________ENCODER________________________##\n",
    "latent_dim = 32\n",
    "\n",
    "nx, ny = 128, 128\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(nx, ny,1))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same',name='layer_E1')(encoder_inputs)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same',name='layer_E2')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',name='layer_E3')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same',name='layer_E4')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_E6')(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(inputs=encoder_inputs, outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entrada Z\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "##dimensiones\n",
    "ndim = 16\n",
    "nfilts = 128\n",
    "\n",
    "## anti-flatten de la última capa convolucional\n",
    "x = layers.Dense(ndim * ndim * nfilts, activation=\"relu\")(latent_inputs)\n",
    "\n",
    "## Reshape para reconstruir la última convolucional\n",
    "x = layers.Reshape((ndim,ndim, nfilts))(x)\n",
    "\n",
    "## Capas convolucionales\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_D1')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_D2')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same',name='layer_D4')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same',name='layer_D6')(x)\n",
    "\n",
    "decoder_outputs = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same',name='layer_D7')(x)\n",
    "\n",
    "## Construcción del decoder\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "opt = tf.optimizers.Adam(learning_rate = 0.000001)\n",
    "#nll = lambda x , rv_x: -rv_x.log_prob(x)\n",
    "vae.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "vae.fit(dataset.batch(16), epochs=2000, \n",
    "                batch_size=16,\n",
    "                         callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Guardar modelohttps://www.tensorflow.org/guide/saved_model?hl=es-419\n",
    "vae.encoder.save('Models/GVAE_encoder_DRY_2_32.h5')\n",
    "vae.decoder.save('Models/GVAE_decoder_DRY_2_32.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
