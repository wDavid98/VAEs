{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 19:46:30.307732: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-11 19:46:30.307765: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-11 19:46:30.311788: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-11 19:46:30.645428: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] =  \"0\"\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "## Librerías\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import cv2 as cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import gc\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 19:46:36.335558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:46:36.397339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:46:36.397504: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "## Uso de GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes secas: 923\n",
      "MF1: 378\n",
      "MF2: 284\n",
      "MF3: 261\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>route_image</th>\n",
       "      <th>label</th>\n",
       "      <th>number</th>\n",
       "      <th>route_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>IMG_20230711_154212_jpg</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>IMG_20230711_154038_jpg</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>IMG_20230601_152414_jpg</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>IMG_20230707_184547_jpg</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>IMG_20230707_181011_jpg</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>IMG_20230711_163407_jpg</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>IMG_20230711_211429_jpg</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>IMG_20230707_164528_jpg</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>IMG_20230711_174546_jpg</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>IMG_20230707_184533_jpg</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>../../../Datasets/Micrografías segmentaciones/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>923 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  \\\n",
       "485  IMG_20230711_154212_jpg   \n",
       "475  IMG_20230711_154038_jpg   \n",
       "25   IMG_20230601_152414_jpg   \n",
       "373  IMG_20230707_184547_jpg   \n",
       "365  IMG_20230707_181011_jpg   \n",
       "..                       ...   \n",
       "578  IMG_20230711_163407_jpg   \n",
       "788  IMG_20230711_211429_jpg   \n",
       "188  IMG_20230707_164528_jpg   \n",
       "667  IMG_20230711_174546_jpg   \n",
       "371  IMG_20230707_184533_jpg   \n",
       "\n",
       "                                           route_image label number  \\\n",
       "485  ../../../Datasets/Micrografías segmentaciones/...     1      1   \n",
       "475  ../../../Datasets/Micrografías segmentaciones/...     1      1   \n",
       "25   ../../../Datasets/Micrografías segmentaciones/...     2      1   \n",
       "373  ../../../Datasets/Micrografías segmentaciones/...     0      6   \n",
       "365  ../../../Datasets/Micrografías segmentaciones/...     0      5   \n",
       "..                                                 ...   ...    ...   \n",
       "578  ../../../Datasets/Micrografías segmentaciones/...     1      3   \n",
       "788  ../../../Datasets/Micrografías segmentaciones/...     2      2   \n",
       "188  ../../../Datasets/Micrografías segmentaciones/...     0      2   \n",
       "667  ../../../Datasets/Micrografías segmentaciones/...     1      5   \n",
       "371  ../../../Datasets/Micrografías segmentaciones/...     0      6   \n",
       "\n",
       "                                            route_mask  \n",
       "485  ../../../Datasets/Micrografías segmentaciones/...  \n",
       "475  ../../../Datasets/Micrografías segmentaciones/...  \n",
       "25   ../../../Datasets/Micrografías segmentaciones/...  \n",
       "373  ../../../Datasets/Micrografías segmentaciones/...  \n",
       "365  ../../../Datasets/Micrografías segmentaciones/...  \n",
       "..                                                 ...  \n",
       "578  ../../../Datasets/Micrografías segmentaciones/...  \n",
       "788  ../../../Datasets/Micrografías segmentaciones/...  \n",
       "188  ../../../Datasets/Micrografías segmentaciones/...  \n",
       "667  ../../../Datasets/Micrografías segmentaciones/...  \n",
       "371  ../../../Datasets/Micrografías segmentaciones/...  \n",
       "\n",
       "[923 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Obtener todas las rutas de las imágenes en el dataset\n",
    "ruta = '../Datasets/Micrografías_segmentadas/secas/*/*/*/*.jpg'\n",
    "rutas_dataset  = glob.glob('../../../Datasets/Micrografías segmentaciones/secas/*/*/*/*.jpg')\n",
    "\n",
    "## Separar rutas\n",
    "mask_list = []\n",
    "image_list = []\n",
    "for ruta in rutas_dataset:    \n",
    "    ruta_list = ruta.split('/')       \n",
    "    clase = ruta_list[6]\n",
    "    number = ruta_list[7]\n",
    "    tipo = ruta_list[8]\n",
    "    name = ruta_list[9].split('.')[0]\n",
    "    \n",
    "    if tipo == 'train':\n",
    "        image_list.append([name,ruta,clase,number])\n",
    "    elif tipo == 'mask_bin':\n",
    "        mask_list.append([name,ruta,clase,number])\n",
    "    else:\n",
    "        None\n",
    "\n",
    "mask_pd = pd.DataFrame(mask_list,columns=['name','route_mask','label','number']).sort_values(by='name')\n",
    "image_pd = pd.DataFrame(image_list,columns=['name','route_image','label','number']).sort_values(by='name')\n",
    "\n",
    "routes_dataset = image_pd.merge(mask_pd,on=['name','label','number'],how='left')\n",
    "\n",
    "routes_dataset.dropna(inplace=True)\n",
    "\n",
    "routes_dataset = routes_dataset.sample(frac = 1)\n",
    "\n",
    "print('Imágenes secas:', np.shape(routes_dataset)[0])\n",
    "print('MF1:', np.shape(routes_dataset[routes_dataset['label']=='MF1'])[0])\n",
    "print('MF2:', np.shape(routes_dataset[routes_dataset['label']=='MF2'])[0])\n",
    "print('MF3:', np.shape(routes_dataset[routes_dataset['label']=='MF3'])[0])\n",
    "\n",
    "char_to_num = {'MF1':'0','MF2':'1','MF3':'2'}\n",
    "\n",
    "routes_dataset['label'].replace(char_to_num,inplace=True)\n",
    "\n",
    "routes_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase MF1: train:  303 , test:  75\n",
      "Clase MF2: train:  228 , test:  56\n",
      "Clase MF3: train:  209 , test:  52\n"
     ]
    }
   ],
   "source": [
    "## Establecer el porcentaje de separación\n",
    "thold1 = int(np.ceil(0.8 * len(routes_dataset[routes_dataset.label=='0'])))\n",
    "thold2 = int(np.ceil(0.8 * len(routes_dataset[routes_dataset.label=='1'])))\n",
    "thold3 = int(np.ceil(0.8 * len(routes_dataset[routes_dataset.label=='2'])))\n",
    "\n",
    "## Separar por clases para entrenamiento\n",
    "train_cu1 = routes_dataset[routes_dataset.label == '0'][0:thold1]\n",
    "train_cu2 = routes_dataset[routes_dataset.label == '1'][0:thold2]\n",
    "train_cu3 = routes_dataset[routes_dataset.label == '2'][0:thold3]\n",
    "\n",
    "## tomar las demás imágenes para test\n",
    "test_cu1 = routes_dataset[routes_dataset.label == '0'][thold1:]\n",
    "test_cu2 = routes_dataset[routes_dataset.label == '1'][thold2:]\n",
    "test_cu3 = routes_dataset[routes_dataset.label == '2'][thold3:]\n",
    "\n",
    "\n",
    "## Constuir un solo dataset de training\n",
    "train_df =  pd.concat([pd.concat([train_cu1,train_cu2]),train_cu3]).sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "\n",
    "## Construir un solo dataset de test\n",
    "test_df = pd.concat([pd.concat([test_cu1,test_cu2]),test_cu3]).sample(frac=1,random_state=100).reset_index(drop=True)\n",
    "\n",
    "## Cantidad de muestras por clase\n",
    "print('Clase MF1: train: ',len(train_cu1),', test: ',len(test_cu1))\n",
    "print('Clase MF2: train: ',len(train_cu2),', test: ',len(test_cu2))\n",
    "print('Clase MF3: train: ',len(train_cu3),', test: ',len(test_cu3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 19:46:48.832465: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:46:48.832720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:46:48.832901: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:46:48.920813: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:46:48.921226: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:46:48.921349: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-11 19:46:48.921438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7666 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:08:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "## Function to get contours and features\n",
    "def get_contours_and_features(binary_map):\n",
    "    #https://docs.opencv.org/4.x/d3/d05/tutorial_py_table_of_contents_contours.html\n",
    "    binary_map = cv2.cvtColor(binary_map, cv2.COLOR_BGR2GRAY)\n",
    "    contours, hierarchy = cv2.findContours(binary_map, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contours_features = []\n",
    "    for contour in contours:\n",
    "        error = 1e-5\n",
    "        moments = cv2.moments(contour)\n",
    "        cx = moments['m10'] / (moments['m00'] + error)\n",
    "        cy = moments['m01'] / (moments['m00'] + error)\n",
    "        center_of_mass = [cx, cy]\n",
    "        x,y,w,h = cv2.boundingRect(contour)        \n",
    "        rect_area = w*h\n",
    "        features = {\n",
    "            'bounding_box': (x,y,w,h),\n",
    "            'area': cv2.contourArea(contour),\n",
    "            'perimeter': cv2.arcLength(contour, True),       \n",
    "            #'solidity': np.float32(cv2.contourArea(contour))/cv2.convexHull(contour),\n",
    "            'equivalent_diameter': np.sqrt(4*cv2.contourArea(contour)/np.pi),            \n",
    "            'moments': moments,\n",
    "            'center_of_mass': center_of_mass,\n",
    "            'contour': contour\n",
    "        }\n",
    "        contours_features.append(features)\n",
    "        del features\n",
    "    #plt.imshow(contours_map, cmap='gray')\n",
    "    return contours_features\n",
    "\n",
    "# function to get a determined property from a list of contours features (area by default)\n",
    "def get_item(contour_features, key='area'):\n",
    "    areas = []\n",
    "    for contour_feature in contour_features:\n",
    "        area =  contour_feature[key]\n",
    "        areas.append(area)\n",
    "    return areas\n",
    "\n",
    "# function to get tensor of one image\n",
    "def load_image(file_name):\n",
    "  raw = tf.io.read_file(file_name)\n",
    "  tensor = tf.io.decode_jpeg(raw,channels=1)\n",
    "  tensor = tf.image.resize(tensor, [128,128])\n",
    "  tensor = tf.cast(tensor, tf.float32) / 255.0\n",
    "  return tensor\n",
    "\n",
    "# function to get set of binary image from image loaded\n",
    "def get_binary_image(filenames):\n",
    "    tensores = []\n",
    "    for filename in filenames:\n",
    "        raw = tf.io.read_file(filename)\n",
    "        tensor = tf.io.decode_jpeg(raw,channels=3)\n",
    "        tensor = tf.image.resize(tensor, [128,128])\n",
    "        tensor = tf.cast(tensor, tf.float32) / 255.0\n",
    "        tensores.append(tensor)\n",
    "    return tensores\n",
    "\n",
    "def get_geometric_atributes(binary_images):\n",
    "    descriptors = []\n",
    "    for binary_img in binary_images:\n",
    "        ## Formato\n",
    "        image = binary_img.numpy().astype(np.uint8)       \n",
    "        \n",
    "        ## Capturar contornos\n",
    "        contour_features = get_contours_and_features(image)\n",
    "        \n",
    "        ## Calcular vector de áreas de poro (todos los poros)\n",
    "        areas = get_item(contour_features, key='area')\n",
    "\n",
    "        ## Calcular vector de perímetros de poro (todo los poros)\n",
    "        pmtro = get_item(contour_features, key='perimeter')\n",
    "\n",
    "        ## Calcular el diametro equivalente de los poros\n",
    "        eq_diameter = get_item(contour_features, key='equivalent_diameter')           \n",
    "\n",
    "        ## Número de poros\n",
    "        npores = np.shape(areas)[0]\n",
    "\n",
    "        descriptor = [np.mean(areas), np.mean(pmtro),np.mean(eq_diameter), npores]\n",
    "        \n",
    "        descriptors.append(descriptor)\n",
    "        \n",
    "    \n",
    "    return descriptors\n",
    "\n",
    "def create_dataset(buffer,file_names, labels, file_mask): \n",
    "  ## Get binary images   \n",
    "  masks = get_binary_image(file_mask)\n",
    "  ## Get geometric atributes from binary images\n",
    "  attributes = get_geometric_atributes(masks)\n",
    "  ## Create dataset from tensors assosiated with labels and attributes\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((file_names,labels,attributes))\n",
    "  ## Shuffle dataset\n",
    "  dataset.shuffle(buffer_size=buffer)\n",
    "  ## Map dataset to load images (a = image, b = label, c = attributes, d = mask)\n",
    "  dataset = dataset.map(lambda file_name, label, attributes : (load_image(file_name), label, attributes))\n",
    "\n",
    "  return dataset\n",
    "\n",
    "file_names = train_df['route_image'].to_numpy()\n",
    "file_mask = train_df['route_mask'].to_numpy()\n",
    "labels = train_df['label'].to_numpy()\n",
    "## Create training dataset using tf.data of 16 images\n",
    "dataset = create_dataset(16,file_names, labels,file_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for i in dataset.batch(16):\n",
    "    a = i[0]\n",
    "    b = i[1]\n",
    "    c = i[2]\n",
    "    #d = i[3]\n",
    "\n",
    "n =  0\n",
    "print(c[n].numpy())\n",
    "print(b[n].numpy())\n",
    "plt.imshow(a[n],cmap='gray')\n",
    "#plt.imshow(d[n],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder convencional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")        \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            \n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data[0])\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction /= tf.reduce_max(reconstruction)\n",
    "            \n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data[0], reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            '''\n",
    "            reconstruction_loss =tf.reduce_mean(\n",
    "                tf.reduce_sum( tf.keras.losses.MeanSquaredError()(data, reconstruction)\n",
    "                             )\n",
    "            )\n",
    "            '''\n",
    "            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))            \n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.reconstruction = reconstruction\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)       \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###_____________________________ENCODER________________________##\n",
    "latent_dim = 16\n",
    "\n",
    "nx, ny = 128, 128\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(nx, ny,1))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same',name='layer_E1')(encoder_inputs)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same',name='layer_E2')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',name='layer_E3')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same',name='layer_E4')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_E6')(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(inputs=encoder_inputs, outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entrada Z\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "##dimensiones\n",
    "ndim = 16\n",
    "nfilts = 128\n",
    "\n",
    "## anti-flatten de la última capa convolucional\n",
    "x = layers.Dense(ndim * ndim * nfilts, activation=\"relu\")(latent_inputs)\n",
    "\n",
    "## Reshape para reconstruir la última convolucional\n",
    "x = layers.Reshape((ndim,ndim, nfilts))(x)\n",
    "\n",
    "## Capas convolucionales\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_D1')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_D2')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same',name='layer_D4')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same',name='layer_D6')(x)\n",
    "\n",
    "decoder_outputs = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same',name='layer_D7')(x)\n",
    "\n",
    "## Construcción del decoder\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "opt = tf.optimizers.Adam(learning_rate = 0.000001)\n",
    "#nll = lambda x , rv_x: -rv_x.log_prob(x)\n",
    "vae.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "vae.fit(dataset.batch(16), epochs=2000, \n",
    "                batch_size=16,\n",
    "                         callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Guardar modelo https://www.tensorflow.org/guide/saved_model?hl=es-419\n",
    "vae.encoder.save('Models2/GVAE_encoder_DRY_1_16.h5')\n",
    "vae.decoder.save('Models2/GVAE_decoder_DRY_1_16.h5')\n",
    "\n",
    "del vae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disentangled variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, regressor, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.regressor = regressor\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")        \n",
    "        self.estimation_loss_tracker = keras.metrics.Mean(name=\"estimation_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.estimation_loss_tracker,            \n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            ## Valores estimados por el encoder\n",
    "            z_mean, z_log_var, z = self.encoder(data[0])\n",
    "            \n",
    "            ## Valores geométricos asociados a los datos\n",
    "            geometrics_features = data[2]\n",
    "\n",
    "            ## Reconstrucción del embebido del encoder\n",
    "            reconstruction = self.decoder(z)            \n",
    "\n",
    "            ## Reducción de la reconstrucción\n",
    "            reconstruction /= tf.reduce_max(reconstruction)\n",
    "\n",
    "            ## Valores estimados apartir del regresor            \n",
    "            estimations = self.regressor(reconstruction)\n",
    "                       \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            ## Error de reconstrucción\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data[0], reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            '''\n",
    "            reconstruction_loss =tf.reduce_mean(\n",
    "                tf.reduce_sum( tf.keras.losses.MeanSquaredError()(data, reconstruction)\n",
    "                             )\n",
    "            )\n",
    "            '''\n",
    "            \n",
    "            ## Error de estimación de valores geométricos\n",
    "                        \n",
    "            estimation_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.mean_squared_error(geometrics_features, estimations), axis=(1)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            \n",
    "            ## Error de divergencia KL\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))   \n",
    "\n",
    "            ## Error total          \n",
    "            total_loss = reconstruction_loss + kl_loss + estimation_loss\n",
    "        \n",
    "        ## Actualización de los gradientes\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "\n",
    "        ## Actualización de lA RECONSTRUCCIÓN\n",
    "        self.reconstruction = reconstruction\n",
    "\n",
    "        ### Actualización de los pesos\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)   \n",
    "        self.estimation_loss_tracker.update_state(estimation_loss)    \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(), \n",
    "            \"ArithmeticError\": self.estimation_loss_tracker.result(),        \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###_____________________________ENCODER________________________##\n",
    "latent_dim = 16\n",
    "\n",
    "nx, ny = 128, 128\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(nx, ny,1))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same',name='layer_E1')(encoder_inputs)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same',name='layer_E2')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',name='layer_E3')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_E4')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_E6')(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(inputs=encoder_inputs, outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entrada Z\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "##dimensiones\n",
    "ndim = 16\n",
    "nfilts = 128\n",
    "\n",
    "## anti-flatten de la última capa convolucional\n",
    "x = layers.Dense(ndim * ndim * nfilts, activation=\"relu\")(latent_inputs)\n",
    "\n",
    "## Reshape para reconstruir la última convolucional\n",
    "x = layers.Reshape((ndim,ndim, nfilts))(x)\n",
    "\n",
    "## Capas convolucionales\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_D1')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_D2')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same',name='layer_D4')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same',name='layer_D6')(x)\n",
    "\n",
    "decoder_outputs = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same',name='layer_D7')(x)\n",
    "\n",
    "## Construcción del decoder\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Estimador de valores geométricos\n",
    "\n",
    "## Input layer\n",
    "regressor_inputs = keras.Input(shape=(128,128,1))\n",
    "\n",
    "## Hidden layers\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same',name='layer_R1')(regressor_inputs)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same',name='layer_R2')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same',name='layer_R3')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same',name='layer_R4')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same',name='layer_R5')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same',name='layer_R6')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "flatten = layers.Flatten()(x)\n",
    "\n",
    "## Output_1 layer\n",
    "regressor_output_area = layers.Dense(1, activation=\"linear\")(flatten)\n",
    "\n",
    "## Output_2 layer\n",
    "regressor_output_perimeter = layers.Dense(1, activation=\"linear\")(flatten)\n",
    "\n",
    "## Output_3 layer\n",
    "regressor_output_diameter = layers.Dense(1, activation=\"linear\")(flatten)\n",
    "\n",
    "## Output_4 layer\n",
    "regressor_output_npores = layers.Dense(1, activation=\"linear\")(flatten)\n",
    "\n",
    "regressor_outputs = [regressor_output_area,regressor_output_perimeter,regressor_output_diameter,regressor_output_npores]\n",
    "\n",
    "## regressor model\n",
    "regressor = keras.Model(regressor_inputs, regressor_outputs, name=\"regressor\")\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder,regressor)\n",
    "opt = tf.optimizers.Adam(learning_rate = 0.000001)\n",
    "#nll = lambda x , rv_x: -rv_x.log_prob(x)\n",
    "vae.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "vae.fit(dataset.batch(16), epochs=2000, \n",
    "                batch_size=16,\n",
    "                         callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Guardar modelohttps://www.tensorflow.org/guide/saved_model?hl=es-419\n",
    "vae.encoder.save('Models2/weakly_GVAE_encoder_DRY_1_16.h5')\n",
    "vae.decoder.save('Models2/weakly_GVAE_decoder_DRY_1_16.h5')\n",
    "vae.regressor.save('Models2/weakly_GVAE_regressor_DRY_1_16.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar para una sola variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, regressor, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.regressor = regressor\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")        \n",
    "        self.estimation_loss_tracker = keras.metrics.Mean(name=\"estimation_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.estimation_loss_tracker,            \n",
    "        ]\n",
    "\n",
    "    def train_step(self, data,property):\n",
    "        with tf.GradientTape() as tape:\n",
    "            ## Valores estimados por el encoder\n",
    "            z_mean, z_log_var, z = self.encoder(data[0])\n",
    "            \n",
    "            ## Valores geométricos asociados a los datos\n",
    "            geometrics_features = data[2]\n",
    "\n",
    "            ## Reconstrucción del embebido del encoder\n",
    "            reconstruction = self.decoder(z)            \n",
    "\n",
    "            ## Reducción de la reconstrucción\n",
    "            reconstruction /= tf.reduce_max(reconstruction)\n",
    "\n",
    "            ## Valores estimados apartir del regresor\n",
    "            estimation = self.regressor(reconstruction)\n",
    "            \n",
    "            ## Error de reconstrucción\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data[0], reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            '''\n",
    "            reconstruction_loss =tf.reduce_mean(\n",
    "                tf.reduce_sum( tf.keras.losses.MeanSquaredError()(data, reconstruction)\n",
    "                             )\n",
    "            )\n",
    "            '''\n",
    "            \n",
    "            ## Error de estimación de valores geométricos\n",
    "            estimation_loss = tf.reduce_mean(tf.keras.losses.MeanSquaredError()(geometrics_features[property], estimation))\n",
    "            \n",
    "            \n",
    "            ## Error de divergencia KL\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))   \n",
    "\n",
    "            ## Error total          \n",
    "            total_loss = reconstruction_loss + kl_loss + estimation_loss\n",
    "        \n",
    "        ## Actualización de los gradientes\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "\n",
    "        ## Actualización de lA RECONSTRUCCIÓN\n",
    "        self.reconstruction = reconstruction\n",
    "\n",
    "        ### Actualización de los pesos\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)   \n",
    "        self.estimation_loss_tracker.update_state(estimation_loss)    \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(), \n",
    "            \"ArithmeticError\": self.estimation_loss_tracker.result(),        \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###_____________________________ENCODER________________________##\n",
    "latent_dim = 32\n",
    "\n",
    "nx, ny = 128, 128\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(nx, ny,1))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same',name='layer_E1')(encoder_inputs)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same',name='layer_E2')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',name='layer_E3')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same',name='layer_E4')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_E6')(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(inputs=encoder_inputs, outputs=[z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entrada Z\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "##dimensiones\n",
    "ndim = 16\n",
    "nfilts = 128\n",
    "\n",
    "## anti-flatten de la última capa convolucional\n",
    "x = layers.Dense(ndim * ndim * nfilts, activation=\"relu\")(latent_inputs)\n",
    "\n",
    "## Reshape para reconstruir la última convolucional\n",
    "x = layers.Reshape((ndim,ndim, nfilts))(x)\n",
    "\n",
    "## Capas convolucionales\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_D1')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_D2')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same',name='layer_D4')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same',name='layer_D6')(x)\n",
    "\n",
    "decoder_outputs = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same',name='layer_D7')(x)\n",
    "\n",
    "## Construcción del decoder\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Estimador de valores geométricos\n",
    "\n",
    "## Input layer\n",
    "regressor_inputs = keras.Input(shape=(128,128,1))\n",
    "\n",
    "## Hidden layers\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same',name='layer_R1')(regressor_inputs)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same',name='layer_R2')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same',name='layer_R3')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same',name='layer_R4')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same',name='layer_R5')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same',name='layer_R6')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "## Output layer\n",
    "flatten = layers.Flatten()(x)\n",
    "regressor_outputs = layers.Dense(4, activation=\"relu\")(flatten)\n",
    "\n",
    "## regressor model\n",
    "regressor = keras.Model(regressor_inputs, regressor_outputs, name=\"regressor\")\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder,regressor)\n",
    "opt = tf.optimizers.Adam(learning_rate = 0.000001)\n",
    "#nll = lambda x , rv_x: -rv_x.log_prob(x)\n",
    "vae.compile(optimizer=opt)\n",
    "\n",
    "\n",
    "vae.fit(dataset.batch(16), epochs=2000, \n",
    "                batch_size=16,\n",
    "                         callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Guardar modelohttps://www.tensorflow.org/guide/saved_model?hl=es-419\n",
    "vae.encoder.save('Models/weakly2_GVAE_encoder_DRY_1_32_p1.h5')\n",
    "vae.decoder.save('Models/weakly2_GVAE_decoder_DRY_1_32_p1.h5')\n",
    "vae.regressor.save('Models/weakly2_GVAE_regressor_DRY_1_32_p1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
